{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d912e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1460, 78)\n",
      "Columns: 78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "train_df = pd.read_csv(\"train_cleaned.csv\")\n",
    "\n",
    "print(\"Shape:\", train_df.shape)\n",
    "print(\"Columns:\", len(train_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c13634",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "    'GarageCars', 'YearBuilt', 'YearRemodAdd', 'FullBath', 'BsmtQual',\n",
    "    'KitchenQual', 'Neighborhood', 'LotArea', 'Fireplaces'\n",
    "]\n",
    "target = 'SalePrice'\n",
    "\n",
    "X = train_df[selected_features]\n",
    "y = train_df[target]\n",
    "\n",
    "# ‚úÖ STEP: Create Price Category Groups\n",
    "# Convert continuous SalePrice into groups (classification)\n",
    "bins = [0, 50000, 100000, 150000, 200000, 250000, 500000, 1000000]\n",
    "labels = ['<50k', '50-100k', '100-150k', '150-200k', '200-250k', '250-500k', '500k+']\n",
    "\n",
    "X = train_df[selected_features]\n",
    "y = pd.cut(train_df['SalePrice'], bins=bins, labels=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c733f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e2d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "numeric_features = [\n",
    "    'GrLivArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "    'GarageCars', 'YearBuilt', 'YearRemodAdd', 'FullBath', 'LotArea', 'Fireplaces'\n",
    "]\n",
    "categorical_features = ['OverallQual', 'BsmtQual', 'KitchenQual', 'Neighborhood']\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "model = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274148d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m feature_names = \u001b[38;5;28mlist\u001b[39m(\u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpreprocessor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features ‡∏´‡∏•‡∏±‡∏á encode:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á feature:\u001b[39m\u001b[33m\"\u001b[39m, feature_names[:\u001b[32m20\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:622\u001b[39m, in \u001b[36mColumnTransformer.get_feature_names_out\u001b[39m\u001b[34m(self, input_features)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[32m    604\u001b[39m \n\u001b[32m    605\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    620\u001b[39m \u001b[33;03m        Transformed feature names.\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m     input_features = _check_feature_names_in(\u001b[38;5;28mself\u001b[39m, input_features)\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# List of tuples (name, feature_names_out)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1754\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "feature_names = list(pipeline.named_steps['preprocessor'].get_feature_names_out())\n",
    "print(\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features ‡∏´‡∏•‡∏±‡∏á encode:\", len(feature_names))\n",
    "print(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á feature:\", feature_names[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1e96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96d11991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "849cec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88640c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7568493150684932\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    100-150k       0.80      0.94      0.86       113\n",
      "    150-200k       0.73      0.72      0.72        71\n",
      "    200-250k       0.50      0.59      0.54        34\n",
      "    250-500k       0.91      0.69      0.78        45\n",
      "     50-100k       0.86      0.50      0.63        24\n",
      "       500k+       1.00      0.33      0.50         3\n",
      "        <50k       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.68      0.54      0.58       292\n",
      "weighted avg       0.77      0.76      0.75       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0540a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(pipeline, \"house_price_pipeline_new.joblib\")\n",
    "print(\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2edd591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Checking file: house_price_pipeline.pkl\n",
      "‚úÖ File loaded successfully!\n",
      "üì¶ Object type: <class 'sklearn.linear_model._base.LinearRegression'>\n",
      "\n",
      "‚öôÔ∏è This object is not a Pipeline.\n",
      "Model parameters:\n",
      "   copy_X: True\n",
      "   fit_intercept: True\n",
      "   n_jobs: None\n",
      "   positive: False\n",
      "   tol: 1e-06\n",
      "\n",
      "üîé Checking file: house_price_pipeline.joblib\n",
      "‚úÖ File loaded successfully!\n",
      "üì¶ Object type: <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "üß± Pipeline Steps:\n",
      "  - preprocess: <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "  - reg: <class 'sklearn.compose._target.TransformedTargetRegressor'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import inspect\n",
    "\n",
    "def inspect_model(file_path):\n",
    "    print(f\"\\nüîé Checking file: {file_path}\")\n",
    "    try:\n",
    "        model = joblib.load(file_path)\n",
    "        print(\"‚úÖ File loaded successfully!\")\n",
    "        print(\"üì¶ Object type:\", type(model))\n",
    "        \n",
    "        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Pipeline\n",
    "        if hasattr(model, 'named_steps'):\n",
    "            print(\"\\nüß± Pipeline Steps:\")\n",
    "            for step_name, step_obj in model.named_steps.items():\n",
    "                print(f\"  - {step_name}: {type(step_obj)}\")\n",
    "            \n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ preprocessor\n",
    "            if 'preprocessor' in model.named_steps:\n",
    "                pre = model.named_steps['preprocessor']\n",
    "                if hasattr(pre, 'transformers'):\n",
    "                    print(\"\\nüìä Transformers in preprocessor:\")\n",
    "                    for name, transformer, cols in pre.transformers:\n",
    "                        print(f\"  ‚Ä¢ {name}: {type(transformer)} (columns: {cols})\")\n",
    "            \n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ model\n",
    "            if 'model' in model.named_steps:\n",
    "                print(\"\\nü§ñ Model details:\")\n",
    "                mdl = model.named_steps['model']\n",
    "                print(\"  - Model type:\", type(mdl))\n",
    "                if hasattr(mdl, 'get_params'):\n",
    "                    print(\"  - Model parameters:\")\n",
    "                    for k, v in list(mdl.get_params().items())[:10]:\n",
    "                        print(f\"     {k}: {v}\")\n",
    "        \n",
    "        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà pipeline\n",
    "        else:\n",
    "            print(\"\\n‚öôÔ∏è This object is not a Pipeline.\")\n",
    "            if hasattr(model, 'get_params'):\n",
    "                print(\"Model parameters:\")\n",
    "                for k, v in list(model.get_params().items())[:10]:\n",
    "                    print(f\"   {k}: {v}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error loading file:\", e)\n",
    "\n",
    "\n",
    "# üîπ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "inspect_model(\"house_price_pipeline.pkl\")\n",
    "inspect_model(\"house_price_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58eabb4",
   "metadata": {},
   "source": [
    "***Train 10 Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold R^2: mean=0.793, std=0.095\n",
      "Train R^2: 0.808\n",
      "Test  R^2: 0.834\n",
      "MAE: 21798.35\n",
      "RMSE: 35685.43\n",
      "‚úÖ Saved: house_price_pipeline_9f_cv10.joblib\n",
      "Features after transform: 33\n",
      "['num__OverallQual' 'num__TotalBsmtSF' 'num__LotArea' 'num__GarageCars'\n",
      " 'num__Fireplaces' 'num__BedroomAbvGr' 'num__GrLivArea' 'num__FullBath'\n",
      " 'cat__Neighborhood_Blmngtn' 'cat__Neighborhood_Blueste'\n",
      " 'cat__Neighborhood_BrDale' 'cat__Neighborhood_BrkSide'\n",
      " 'cat__Neighborhood_ClearCr' 'cat__Neighborhood_CollgCr'\n",
      " 'cat__Neighborhood_Crawfor']\n"
     ]
    }
   ],
   "source": [
    "# 0) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# 1) Load data\n",
    "df = pd.read_csv(\"train_cleaned.csv\")\n",
    "\n",
    "# 2) Define features/target (SalePrice = target)\n",
    "feature_cols = [\n",
    "    \"OverallQual\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"LotArea\",\n",
    "    \"GarageCars\",\n",
    "    \"Fireplaces\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"Neighborhood\",\n",
    "    \"GrLivArea\",\n",
    "    \"FullBath\",\n",
    "]\n",
    "target_col = \"SalePrice\"\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].astype(float)\n",
    "\n",
    "# 3) Enforce dtypes (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö front-end)\n",
    "numeric_int_cols = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "cat_cols = [\"Neighborhood\"]\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á numeric ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏Å‡∏±‡∏ô‡∏û‡∏±‡∏á‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏á‡∏°‡∏≤)\n",
    "for c in numeric_int_cols:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "# Neighborhood ‡πÄ‡∏õ‡πá‡∏ô string\n",
    "X[cat_cols] = X[cat_cols].astype(str)\n",
    "\n",
    "# 4) Basic sanity clips (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ dropdown/front-end ‡∏°‡∏µ guardrail)\n",
    "X[\"OverallQual\"] = X[\"OverallQual\"].clip(1, 10)\n",
    "X[\"GarageCars\"]  = X[\"GarageCars\"].clip(0, 4)\n",
    "X[\"FullBath\"]    = X[\"FullBath\"].clip(lower=0)\n",
    "X[\"Fireplaces\"]  = X[\"Fireplaces\"].clip(lower=0)\n",
    "X[\"BedroomAbvGr\"]= X[\"BedroomAbvGr\"].clip(lower=0)\n",
    "X[\"TotalBsmtSF\"] = X[\"TotalBsmtSF\"].clip(lower=0)\n",
    "X[\"GrLivArea\"]   = X[\"GrLivArea\"].clip(lower=0)\n",
    "X[\"LotArea\"]     = X[\"LotArea\"].clip(lower=0)\n",
    "\n",
    "# 5) Preprocessor\n",
    "num_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, numeric_int_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6) Model\n",
    "model = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# 7) 10-fold CV score (R^2)\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"r2\")\n",
    "print(f\"10-fold R^2: mean={cv_scores.mean():.3f}, std={cv_scores.std():.3f}\")\n",
    "\n",
    "# 8) Hold-out test (optional ‡πÅ‡∏ï‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ over/underfit)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred_train = pipeline.predict(X_train)\n",
    "pred_test  = pipeline.predict(X_test)\n",
    "\n",
    "rmse = lambda a,b: np.sqrt(((a-b)**2).mean())\n",
    "\n",
    "print(f\"Train R^2: {r2_score(y_train, pred_train):.3f}\")\n",
    "print(f\"Test  R^2: {r2_score(y_test,  pred_test):.3f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, pred_test):.2f}\")\n",
    "print(f\"RMSE: {rmse(y_test, pred_test):.2f}\")\n",
    "\n",
    "# 9) Fit on all data & save\n",
    "pipeline.fit(X, y)\n",
    "joblib.dump(pipeline, \"house_price_pipeline_9f_cv10.joblib\")\n",
    "print(\"‚úÖ Saved: house_price_pipeline_9f_cv10.joblib\")\n",
    "\n",
    "# (Optional) ‡∏î‡∏π‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß\n",
    "feat_names = pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "print(\"Features after transform:\", len(feat_names))\n",
    "print(feat_names[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d10d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ROOT OBJECT ===\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "=== PIPELINE STEPS ===\n",
      "- preprocessor: ColumnTransformer\n",
      "- model: RidgeCV\n",
      "\n",
      "=== COLUMN TRANSFORMER ===\n",
      "remainder: drop\n",
      "* transformer: num -> Pipeline on ['OverallQual', 'TotalBsmtSF', 'LotArea', 'GarageCars', 'Fireplaces', 'BedroomAbvGr', 'GrLivArea', 'FullBath']\n",
      "* transformer: cat -> Pipeline on ['Neighborhood']\n",
      "\n",
      "feature_names_out (sample): ['num__OverallQual' 'num__TotalBsmtSF' 'num__LotArea' 'num__GarageCars'\n",
      " 'num__Fireplaces' 'num__BedroomAbvGr' 'num__GrLivArea' 'num__FullBath'\n",
      " 'cat__Neighborhood_Blmngtn' 'cat__Neighborhood_Blueste'\n",
      " 'cat__Neighborhood_BrDale' 'cat__Neighborhood_BrkSide'\n",
      " 'cat__Neighborhood_ClearCr' 'cat__Neighborhood_CollgCr'\n",
      " 'cat__Neighborhood_Crawfor' 'cat__Neighborhood_Edwards'\n",
      " 'cat__Neighborhood_Gilbert' 'cat__Neighborhood_IDOTRR'\n",
      " 'cat__Neighborhood_MeadowV' 'cat__Neighborhood_Mitchel'\n",
      " 'cat__Neighborhood_NAmes' 'cat__Neighborhood_NPkVill'\n",
      " 'cat__Neighborhood_NWAmes' 'cat__Neighborhood_NoRidge'\n",
      " 'cat__Neighborhood_NridgHt' 'cat__Neighborhood_OldTown'\n",
      " 'cat__Neighborhood_SWISU' 'cat__Neighborhood_Sawyer'\n",
      " 'cat__Neighborhood_SawyerW' 'cat__Neighborhood_Somerst'\n",
      " 'cat__Neighborhood_StoneBr' 'cat__Neighborhood_Timber'\n",
      " 'cat__Neighborhood_Veenker']\n",
      "total transformed features: 33\n",
      "\n",
      "=== FINAL ESTIMATOR ===\n",
      "RidgeCV\n",
      "params (subset):\n",
      "   alpha_per_target = False\n",
      "   alphas = [0.1, 1.0, 10.0]\n",
      "   cv = 5\n",
      "   fit_intercept = True\n",
      "   gcv_mode = None\n",
      "   scoring = None\n",
      "   store_cv_results = False\n",
      "\n",
      "coef_: (len=33) [ 22411.49143317   8876.83974931   4946.72785504   9382.87613733\n",
      "   4047.08084229  -4555.03347978  25035.33202535   1220.14293466\n",
      " -17268.87774955 -28436.17713974]\n",
      "\n",
      "intercept_: 180874.6617076188\n",
      "\n",
      "n_features_in_: 33\n"
     ]
    }
   ],
   "source": [
    "import joblib, pickle, pprint, sys\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"house_price_pipeline_9f_cv10.joblib\")  # ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π\n",
    "obj = joblib.load(p) if p.suffix == \".joblib\" else pickle.load(open(p, \"rb\"))\n",
    "\n",
    "print(\"=== ROOT OBJECT ===\")\n",
    "print(type(obj))\n",
    "\n",
    "# ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Pipeline:\n",
    "try:\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.base import BaseEstimator\n",
    "except Exception as e:\n",
    "    Pipeline = ColumnTransformer = BaseEstimator = None\n",
    "\n",
    "if Pipeline and isinstance(obj, Pipeline):\n",
    "    print(\"\\n=== PIPELINE STEPS ===\")\n",
    "    for name, est in obj.steps:\n",
    "        print(f\"- {name}: {type(est).__name__}\")\n",
    "\n",
    "    ct = None\n",
    "    for name, est in obj.steps:\n",
    "        if ColumnTransformer and isinstance(est, ColumnTransformer):\n",
    "            ct = est\n",
    "            break\n",
    "\n",
    "    if ct:\n",
    "        print(\"\\n=== COLUMN TRANSFORMER ===\")\n",
    "        print(\"remainder:\", ct.remainder)\n",
    "        for name, tr, cols in ct.transformers:\n",
    "            print(f\"* transformer: {name} -> {type(tr).__name__} on {cols}\")\n",
    "\n",
    "        try:\n",
    "            fno = ct.get_feature_names_out()\n",
    "            print(\"\\nfeature_names_out (sample):\", fno[:50])\n",
    "            print(\"total transformed features:\", len(fno))\n",
    "        except Exception as e:\n",
    "            print(\"\\n(get_feature_names_out) ->\", e)\n",
    "\n",
    "   \n",
    "    final_est = obj.steps[-1][1]\n",
    "    print(\"\\n=== FINAL ESTIMATOR ===\")\n",
    "    print(type(final_est).__name__)\n",
    "    try:\n",
    "        params = final_est.get_params()\n",
    "        print(\"params (subset):\")\n",
    "        for k in list(params)[:30]:\n",
    "            print(\"  \", k, \"=\", params[k])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    for attr in [\"coef_\", \"intercept_\", \"feature_importances_\", \"n_features_in_\"]:\n",
    "        if hasattr(final_est, attr):\n",
    "            val = getattr(final_est, attr)\n",
    "            try:\n",
    "                size = len(val)\n",
    "                show = val[:10] if size > 10 else val\n",
    "                print(f\"\\n{attr}: (len={size})\", show)\n",
    "            except TypeError:\n",
    "                print(f\"\\n{attr}:\", val)\n",
    "\n",
    "else:\n",
    "    print(\"\\n=== GENERIC OBJECT INFO ===\")\n",
    "    if hasattr(obj, \"get_params\"):\n",
    "        print(\"Sklearn estimator params keys:\", list(obj.get_params().keys())[:30])\n",
    "    elif isinstance(obj, dict):\n",
    "        print(\"dict keys:\", list(obj.keys()))\n",
    "    else:\n",
    "        pprint.pprint(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31733629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\n",
      "Train RMSE: 34,471.10 | MAE: 19,641.75 | R2: 0.801\n",
      " Test RMSE: 29,620.65 | MAE: 19,180.85 | R2: 0.886\n",
      "\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: house_price_pipeline.joblib\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: features.json\n",
      "\n",
      "=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ===\n",
      "Case 1: {'LotArea': 8500, 'OverallQual': 6, 'Neighborhood': 'CollgCr'}\n",
      "‚Üí Predicted SalePrice: 184,608.38 USD\n",
      "\n",
      "Case 2: {'OverallQual': 7, 'GrLivArea': 1800, 'FullBath': 2, 'BedroomAbvGr': 3, 'Neighborhood': 'NAmes'}\n",
      "‚Üí Predicted SalePrice: 194,257.68 USD\n",
      "\n",
      "Case 3: {'LotArea': 12000, 'TotalBsmtSF': 900, 'GarageCars': 2, 'GrLivArea': 2200, 'FullBath': 2}\n",
      "‚Üí Predicted SalePrice: 190,951.88 USD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_house_price.py\n",
    "# ====================\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô (Regression) ‡∏à‡∏≤‡∏Å Kaggle (train_cleaned.csv)\n",
    "# - ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå 9 ‡∏ï‡∏±‡∏ß + ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ SalePrice (log-transform)\n",
    "# - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ö‡∏ô test split\n",
    "# - ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô house_price_pipeline.joblib ‡πÅ‡∏•‡∏∞ features.json\n",
    "# - ‡∏°‡∏µ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡πÄ‡∏Ñ‡∏™\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 1) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ------------------------\n",
    "DATA_PATH = \"train_cleaned.csv\"\n",
    "assert Path(DATA_PATH).exists(), f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DATA_PATH} ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# 2) ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå/‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢\n",
    "# ------------------------\n",
    "FEATURES_NUM = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "FEATURES_CAT = [\"Neighborhood\"]\n",
    "FEATURES = FEATURES_NUM + FEATURES_CAT\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà target ‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏≠‡∏≠‡∏Å (‡∏Å‡∏±‡∏ô error)\n",
    "df = df.dropna(subset=[TARGET])\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = np.log1p(df[TARGET].astype(float))  # ‡πÅ‡∏õ‡∏•‡∏á log1p ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "\n",
    "# ------------------------\n",
    "# 3) ‡πÅ‡∏ö‡πà‡∏á train/test\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4) Preprocessor (impute + encode + scale)\n",
    "# ------------------------\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_tf, FEATURES_NUM),\n",
    "    (\"cat\", cat_tf, FEATURES_CAT),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "# ------------------------\n",
    "model = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "\n",
    "# ------------------------\n",
    "# 6) Pipeline ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "# ------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", pre),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 7) ‡πÄ‡∏ó‡∏£‡∏ô\n",
    "# ------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------\n",
    "# 8) ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö sklearn ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤)\n",
    "# ------------------------\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å log ‚Üí ‡∏™‡πÄ‡∏Å‡∏•‡∏à‡∏£‡∏¥‡∏á\n",
    "pred_train = np.expm1(pipe.predict(X_train))\n",
    "true_train = np.expm1(y_train)\n",
    "\n",
    "pred_test = np.expm1(pipe.predict(X_test))\n",
    "true_test = np.expm1(y_test)\n",
    "\n",
    "# MSE/MAE/R2 train\n",
    "mse_tr  = mean_squared_error(true_train, pred_train)  # ‡πÑ‡∏°‡πà‡∏°‡∏µ squared= ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ\n",
    "rmse_tr = np.sqrt(mse_tr)\n",
    "mae_tr  = mean_absolute_error(true_train, pred_train)\n",
    "r2_tr   = r2_score(true_train, pred_train)\n",
    "\n",
    "# MSE/MAE/R2 test\n",
    "mse_te  = mean_squared_error(true_test, pred_test)\n",
    "rmse_te = np.sqrt(mse_te)\n",
    "mae_te  = mean_absolute_error(true_test, pred_test)\n",
    "r2_te   = r2_score(true_test, pred_test)\n",
    "\n",
    "print(\"=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\")\n",
    "print(f\"Train RMSE: {rmse_tr:,.2f} | MAE: {mae_tr:,.2f} | R2: {r2_tr:.3f}\")\n",
    "print(f\" Test RMSE: {rmse_te:,.2f} | MAE: {mae_te:,.2f} | R2: {r2_te:.3f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 9) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• + ‡πÄ‡∏°‡∏ó‡∏≤‡∏î‡∏≤‡∏ó‡∏≤\n",
    "# ------------------------\n",
    "MODEL_PATH = \"house_price_pipeline_Train_10.joblib\"\n",
    "META_PATH = \"features.json\"\n",
    "\n",
    "joblib.dump(pipe, MODEL_PATH)\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"num\": FEATURES_NUM, \"cat\": FEATURES_CAT}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: {META_PATH}\")\n",
    "\n",
    "# ------------------------\n",
    "# 10) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏Å‡πá‡πÑ‡∏î‡πâ)\n",
    "# ------------------------\n",
    "def predict_saleprice(input_dict: dict) -> float:\n",
    "    \"\"\"\n",
    "    input_dict: key ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö FEATURES (‡πÉ‡∏™‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÑ‡∏î‡πâ)\n",
    "      ‡πÄ‡∏ä‡πà‡∏ô {\"LotArea\": 8500, \"OverallQual\": 6, \"Neighborhood\": \"CollgCr\"}\n",
    "    \"\"\"\n",
    "    row = {f: input_dict.get(f, None) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "    y_log = pipe.predict(X_one)[0]\n",
    "    y_hat = float(np.expm1(y_log))\n",
    "    return round(y_hat, 2)\n",
    "\n",
    "# ------------------------\n",
    "# 11) ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡πÄ‡∏Ñ‡∏™ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)\n",
    "# ------------------------\n",
    "examples = [\n",
    "    {\"LotArea\": 8500, \"OverallQual\": 6, \"Neighborhood\": \"CollgCr\"},\n",
    "    {\"OverallQual\": 7, \"GrLivArea\": 1800, \"FullBath\": 2, \"BedroomAbvGr\": 3, \"Neighborhood\": \"NAmes\"},\n",
    "    {\"LotArea\": 12000, \"TotalBsmtSF\": 900, \"GarageCars\": 2, \"GrLivArea\": 2200, \"FullBath\": 2},\n",
    "]\n",
    "\n",
    "print(\"\\n=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ===\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    print(f\"Case {i}: {ex}\")\n",
    "    print(\"‚Üí Predicted SalePrice:\", f\"{predict_saleprice(ex):,.2f}\", \"USD\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "007c5fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\n",
      "Train RMSE: 34,471.10 | MAE: 19,641.75 | R2: 0.801\n",
      " Test RMSE: 29,620.65 | MAE: 19,180.85 | R2: 0.886\n",
      "\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: house_price_pipeline_Train_10.joblib\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: features.json\n",
      "\n",
      "=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must specify axis=0 or 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23240\\3998245754.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    214\u001b[39m ]\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m print(\u001b[33m\"\\n=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\"\u001b[39m)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, ex \u001b[38;5;28;01min\u001b[39;00m enumerate(examples, \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     out = predict_with_report(ex)\n\u001b[32m    219\u001b[39m     print(f\"Case {i}: input={ex}\")\n\u001b[32m    220\u001b[39m     print(f\"‚Üí Predicted SalePrice: {out[\u001b[33m'predicted_price_usd'\u001b[39m]:,.2f} USD\")\n\u001b[32m    221\u001b[39m \n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23240\\3998245754.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_dict)\u001b[39m\n\u001b[32m    181\u001b[39m         features_filled:   ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≠‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ (imputed)\n\u001b[32m    182\u001b[39m     - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå\n\u001b[32m    183\u001b[39m     \"\"\"\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# ‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå (‡πÑ‡∏ß‡πâ‡πÇ‡∏ä‡∏ß‡πå)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     used_after_impute = impute_preview(pipe, input_dict)\n\u001b[32m    186\u001b[39m \n\u001b[32m    187\u001b[39m     \u001b[38;5;66;03m# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö predict (‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ pipeline impute ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô‚Äî‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ú‡∏•)\u001b[39;00m\n\u001b[32m    188\u001b[39m     row = {f: input_dict.get(f, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;28;01min\u001b[39;00m FEATURES}\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23240\\3998245754.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(pipe, row_dict)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric\u001b[39;00m\n\u001b[32m    146\u001b[39m     num_stats = pd.Series(num_imp.statistics_, index=FEATURES_NUM) \u001b[38;5;28;01mif\u001b[39;00m FEATURES_NUM \u001b[38;5;28;01melse\u001b[39;00m pd.Series(dtype=float)\n\u001b[32m    147\u001b[39m     X_num = X_one[FEATURES_NUM].copy().apply(pd.to_numeric, errors=\u001b[33m\"coerce\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m FEATURES_NUM \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m FEATURES_NUM:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         X_num = X_num.where(~X_num.isna(), num_stats)\n\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical\u001b[39;00m\n\u001b[32m    152\u001b[39m     cat_stats = pd.Series(cat_imp.statistics_, index=FEATURES_CAT) \u001b[38;5;28;01mif\u001b[39;00m FEATURES_CAT \u001b[38;5;28;01melse\u001b[39;00m pd.Series(dtype=object)\n",
      "\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, cond, other, inplace, axis, level)\u001b[39m\n\u001b[32m  10999\u001b[39m                         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m  11000\u001b[39m                     )\n\u001b[32m  11001\u001b[39m \n\u001b[32m  11002\u001b[39m         other = common.apply_if_callable(other, self)\n\u001b[32m> \u001b[39m\u001b[32m11003\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._where(cond, other, inplace, axis, level)\n",
      "\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, cond, other, inplace, axis, level, warn)\u001b[39m\n\u001b[32m  10707\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, NDFrame):\n\u001b[32m  10708\u001b[39m             \u001b[38;5;66;03m# align with me\u001b[39;00m\n\u001b[32m  10709\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m other.ndim <= self.ndim:\n\u001b[32m  10710\u001b[39m                 \u001b[38;5;66;03m# CoW: Make sure reference is not kept alive\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m10711\u001b[39m                 other = self.align(\n\u001b[32m  10712\u001b[39m                     other,\n\u001b[32m  10713\u001b[39m                     join=\u001b[33m\"left\"\u001b[39m,\n\u001b[32m  10714\u001b[39m                     axis=axis,\n",
      "\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[39m\n\u001b[32m  10462\u001b[39m                 fill_axis=fill_axis,\n\u001b[32m  10463\u001b[39m             )\n\u001b[32m  10464\u001b[39m \n\u001b[32m  10465\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m isinstance(other, ABCSeries):\n\u001b[32m> \u001b[39m\u001b[32m10466\u001b[39m             left, _right, join_index = self._align_series(\n\u001b[32m  10467\u001b[39m                 other,\n\u001b[32m  10468\u001b[39m                 join=join,\n\u001b[32m  10469\u001b[39m                 axis=axis,\n",
      "\u001b[32mc:\\Users\\NBODT\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[39m\n\u001b[32m  10568\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m  10569\u001b[39m             copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m  10570\u001b[39m \n\u001b[32m  10571\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28;01mnot\u001b[39;00m is_series \u001b[38;5;28;01mand\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mor\u001b[39;00m axis \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]:\n\u001b[32m> \u001b[39m\u001b[32m10572\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Must specify axis=0 or 1\"\u001b[39m)\n\u001b[32m  10573\u001b[39m \n\u001b[32m  10574\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_series \u001b[38;5;28;01mand\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n\u001b[32m  10575\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"cannot align series to a series other than axis 0\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Must specify axis=0 or 1"
     ]
    }
   ],
   "source": [
    "# train_house_price.py\n",
    "# ====================\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô (Regression) ‡∏à‡∏≤‡∏Å Kaggle (train_cleaned.csv)\n",
    "# - ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå 9 ‡∏ï‡∏±‡∏ß + ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ SalePrice (log-transform)\n",
    "# - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ö‡∏ô test split\n",
    "# - ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô house_price_pipeline_Train_10.joblib ‡πÅ‡∏•‡∏∞ features.json\n",
    "# - ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö \"‡πÇ‡∏ä‡∏ß‡πå‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å\" ‡πÅ‡∏•‡∏∞ \"‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 1) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ------------------------\n",
    "DATA_PATH = \"train_cleaned.csv\"\n",
    "assert Path(DATA_PATH).exists(), f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DATA_PATH} ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# 2) ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå/‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢\n",
    "# ------------------------\n",
    "FEATURES_NUM = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "FEATURES_CAT = [\"Neighborhood\"]\n",
    "FEATURES = FEATURES_NUM + FEATURES_CAT\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà target ‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏≠‡∏≠‡∏Å (‡∏Å‡∏±‡∏ô error)\n",
    "df = df.dropna(subset=[TARGET])\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = np.log1p(df[TARGET].astype(float))  # ‡πÅ‡∏õ‡∏•‡∏á log1p ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "\n",
    "# ------------------------\n",
    "# 3) ‡πÅ‡∏ö‡πà‡∏á train/test\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4) Preprocessor (impute + encode + scale)\n",
    "# ------------------------\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_tf, FEATURES_NUM),\n",
    "    (\"cat\", cat_tf, FEATURES_CAT),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "# ------------------------\n",
    "model = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "\n",
    "# ------------------------\n",
    "# 6) Pipeline ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "# ------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", pre),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 7) ‡πÄ‡∏ó‡∏£‡∏ô\n",
    "# ------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------\n",
    "# 8) ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö sklearn ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤)\n",
    "# ------------------------\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å log ‚Üí ‡∏™‡πÄ‡∏Å‡∏•‡∏à‡∏£‡∏¥‡∏á\n",
    "pred_train = np.expm1(pipe.predict(X_train))\n",
    "true_train = np.expm1(y_train)\n",
    "\n",
    "pred_test = np.expm1(pipe.predict(X_test))\n",
    "true_test = np.expm1(y_test)\n",
    "\n",
    "# MSE/MAE/R2 train\n",
    "mse_tr  = mean_squared_error(true_train, pred_train)  # ‡πÑ‡∏°‡πà‡∏°‡∏µ squared=\n",
    "rmse_tr = np.sqrt(mse_tr)\n",
    "mae_tr  = mean_absolute_error(true_train, pred_train)\n",
    "r2_tr   = r2_score(true_train, pred_train)\n",
    "\n",
    "# MSE/MAE/R2 test\n",
    "mse_te  = mean_squared_error(true_test, pred_test)\n",
    "rmse_te = np.sqrt(mse_te)\n",
    "mae_te  = mean_absolute_error(true_test, pred_test)\n",
    "r2_te   = r2_score(true_test, pred_test)\n",
    "\n",
    "print(\"=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\")\n",
    "print(f\"Train RMSE: {rmse_tr:,.2f} | MAE: {mae_tr:,.2f} | R2: {r2_tr:.3f}\")\n",
    "print(f\" Test RMSE: {rmse_te:,.2f} | MAE: {mae_te:,.2f} | R2: {r2_te:.3f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 9) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• + ‡πÄ‡∏°‡∏ó‡∏≤‡∏î‡∏≤‡∏ó‡∏≤\n",
    "# ------------------------\n",
    "MODEL_PATH = \"house_price_pipeline_Train_10.joblib\"\n",
    "META_PATH = \"features.json\"\n",
    "\n",
    "joblib.dump(pipe, MODEL_PATH)\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"num\": FEATURES_NUM, \"cat\": FEATURES_CAT}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: {META_PATH}\")\n",
    "\n",
    "# ------------------------\n",
    "# 10) Helper: preview ‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå \"‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß\"\n",
    "# ------------------------\n",
    "def impute_preview(pipe: Pipeline, row_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏∑‡∏ô dict ‡∏Ç‡∏≠‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á 9 ‡∏ï‡∏±‡∏ß '‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß' (‡∏Å‡πà‡∏≠‡∏ô scale/one-hot)\n",
    "    \"\"\"\n",
    "    row = {f: row_dict.get(f, np.nan) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "\n",
    "    pre: ColumnTransformer = pipe.named_steps[\"preprocessor\"]\n",
    "    # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á imputer ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "    num_imp: SimpleImputer = pre.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "    cat_imp: SimpleImputer = pre.named_transformers_[\"cat\"].named_steps[\"imputer\"]\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric\n",
    "    num_stats = pd.Series(num_imp.statistics_, index=FEATURES_NUM) if FEATURES_NUM else pd.Series(dtype=float)\n",
    "    X_num = X_one[FEATURES_NUM].copy().apply(pd.to_numeric, errors=\"coerce\") if FEATURES_NUM else pd.DataFrame()\n",
    "    if FEATURES_NUM:\n",
    "        X_num = X_num.where(~X_num.isna(), num_stats)\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical\n",
    "    cat_stats = pd.Series(cat_imp.statistics_, index=FEATURES_CAT) if FEATURES_CAT else pd.Series(dtype=object)\n",
    "    X_cat = X_one[FEATURES_CAT].copy() if FEATURES_CAT else pd.DataFrame()\n",
    "    if FEATURES_CAT:\n",
    "        X_cat = X_cat.where(~X_cat.isna(), cat_stats)\n",
    "\n",
    "    if FEATURES_NUM and FEATURES_CAT:\n",
    "        X_imp = pd.concat([X_num, X_cat], axis=1)[FEATURES]\n",
    "    elif FEATURES_NUM:\n",
    "        X_imp = X_num[FEATURES]\n",
    "    else:\n",
    "        X_imp = X_cat[FEATURES]\n",
    "\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏™‡∏ß‡∏¢ ‡πÜ\n",
    "    out = {}\n",
    "    for k, v in X_imp.iloc[0].to_dict().items():\n",
    "        if k in FEATURES_NUM:\n",
    "            out[k] = None if pd.isna(v) else float(v)\n",
    "        else:\n",
    "            out[k] = None if (isinstance(v, float) and pd.isna(v)) else str(v)\n",
    "    return out\n",
    "\n",
    "# ------------------------\n",
    "# 11) ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå + ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô \"‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß/‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "# ------------------------\n",
    "def predict_with_report(input_dict: dict):\n",
    "    \"\"\"\n",
    "    - ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ (expm1)\n",
    "    - ‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô:\n",
    "        features_provided: ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å\n",
    "        features_filled:   ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≠‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ (imputed)\n",
    "    - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå\n",
    "    \"\"\"\n",
    "    # ‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå (‡πÑ‡∏ß‡πâ‡πÇ‡∏ä‡∏ß‡πå)\n",
    "    used_after_impute = impute_preview(pipe, input_dict)\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö predict (‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ pipeline impute ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô‚Äî‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ú‡∏•)\n",
    "    row = {f: input_dict.get(f, None) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "    y_log = pipe.predict(X_one)[0]\n",
    "    y_hat = float(np.expm1(y_log))\n",
    "\n",
    "    # ‡∏à‡∏±‡∏î‡πÅ‡∏¢‡∏Å \"‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß\" vs \"‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "    provided, filled = {}, {}\n",
    "    for f in FEATURES:\n",
    "        if f in input_dict and input_dict[f] is not None:\n",
    "            provided[f] = used_after_impute[f]  # ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á (‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡πÅ‡∏Ñ‡∏™/‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß)\n",
    "        else:\n",
    "            filled[f] = used_after_impute[f]     # ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏¥‡∏°\n",
    "\n",
    "    return {\n",
    "        \"predicted_price_usd\": round(y_hat, 2),\n",
    "        \"features_provided\": provided,\n",
    "        \"features_filled\": filled\n",
    "    }\n",
    "\n",
    "# ------------------------\n",
    "# 12) ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡πÄ‡∏Ñ‡∏™ (‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏ï‡πá‡∏°)\n",
    "# ------------------------\n",
    "examples = [\n",
    "    {\"LotArea\": 8500, \"OverallQual\": 6, \"Neighborhood\": \"CollgCr\"},\n",
    "    {\"OverallQual\": 7, \"GrLivArea\": 1800, \"FullBath\": 2, \"BedroomAbvGr\": 3, \"Neighborhood\": \"NAmes\"},\n",
    "    {\"LotArea\": 12000, \"TotalBsmtSF\": 900, \"GarageCars\": 2, \"GrLivArea\": 2200, \"FullBath\": 2},\n",
    "]\n",
    "\n",
    "print(\"\\n=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    out = predict_with_report(ex)\n",
    "    print(f\"Case {i}: input={ex}\")\n",
    "    print(f\"‚Üí Predicted SalePrice: {out['predicted_price_usd']:,.2f} USD\")\n",
    "\n",
    "    print(\"‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\")\n",
    "    if out[\"features_provided\"]:\n",
    "        for k, v in out[\"features_provided\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏¢)\")\n",
    "\n",
    "    print(\"‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\")\n",
    "    if out[\"features_filled\"]:\n",
    "        for k, v in out[\"features_filled\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏£‡∏ö)\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85f4231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\n",
      "Train RMSE: 34,471.10 | MAE: 19,641.75 | R2: 0.801\n",
      " Test RMSE: 29,620.65 | MAE: 19,180.85 | R2: 0.886\n",
      "\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: house_price_pipeline_Train_10.joblib\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: features.json\n",
      "\n",
      "=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\n",
      "Case 1: input={'LotArea': 8500}\n",
      "‚Üí Predicted SalePrice: 169,700.75 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - LotArea: 8500.0\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - OverallQual: 6.0\n",
      "   - TotalBsmtSF: 997.5\n",
      "   - GarageCars: 2.0\n",
      "   - Fireplaces: 1.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - GrLivArea: 1473.0\n",
      "   - FullBath: 2.0\n",
      "   - Neighborhood: NAmes\n",
      "\n",
      "Case 2: input={'LotArea': 8500}\n",
      "‚Üí Predicted SalePrice: 169,700.75 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - LotArea: 8500.0\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - OverallQual: 6.0\n",
      "   - TotalBsmtSF: 997.5\n",
      "   - GarageCars: 2.0\n",
      "   - Fireplaces: 1.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - GrLivArea: 1473.0\n",
      "   - FullBath: 2.0\n",
      "   - Neighborhood: NAmes\n",
      "\n",
      "Case 3: input={'LotArea': 8500}\n",
      "‚Üí Predicted SalePrice: 169,700.75 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - LotArea: 8500.0\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - OverallQual: 6.0\n",
      "   - TotalBsmtSF: 997.5\n",
      "   - GarageCars: 2.0\n",
      "   - Fireplaces: 1.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - GrLivArea: 1473.0\n",
      "   - FullBath: 2.0\n",
      "   - Neighborhood: NAmes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_house_price.py\n",
    "# ====================\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô (Regression) ‡∏à‡∏≤‡∏Å Kaggle (train_cleaned.csv)\n",
    "# - ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå 9 ‡∏ï‡∏±‡∏ß + ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ SalePrice (log-transform)\n",
    "# - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ö‡∏ô test split\n",
    "# - ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô house_price_pipeline_Train_10.joblib ‡πÅ‡∏•‡∏∞ features.json\n",
    "# - ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö \"‡πÇ‡∏ä‡∏ß‡πå‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å\" ‡πÅ‡∏•‡∏∞ \"‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ (imputed)\"\n",
    "# - ‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å pandas: ‡πÉ‡∏ä‡πâ fillna(series) ‡πÅ‡∏ó‡∏ô where(...)\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from typing import Dict\n",
    "\n",
    "# ------------------------\n",
    "# 1) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ------------------------\n",
    "DATA_PATH = \"train_cleaned.csv\"\n",
    "assert Path(DATA_PATH).exists(), f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DATA_PATH} ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# 2) ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå/‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢\n",
    "# ------------------------\n",
    "FEATURES_NUM = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "FEATURES_CAT = [\"Neighborhood\"]\n",
    "FEATURES = FEATURES_NUM + FEATURES_CAT\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà target ‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏≠‡∏≠‡∏Å (‡∏Å‡∏±‡∏ô error)\n",
    "df = df.dropna(subset=[TARGET])\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = np.log1p(df[TARGET].astype(float))  # ‡πÅ‡∏õ‡∏•‡∏á log1p ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "\n",
    "# ------------------------\n",
    "# 3) ‡πÅ‡∏ö‡πà‡∏á train/test\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4) Preprocessor (impute + encode + scale)\n",
    "# ------------------------\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_tf, FEATURES_NUM),\n",
    "    (\"cat\", cat_tf, FEATURES_CAT),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "# ------------------------\n",
    "model = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "\n",
    "# ------------------------\n",
    "# 6) Pipeline ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "# ------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", pre),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 7) ‡πÄ‡∏ó‡∏£‡∏ô\n",
    "# ------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------\n",
    "# 8) ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö sklearn ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤)\n",
    "# ------------------------\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å log ‚Üí ‡∏™‡πÄ‡∏Å‡∏•‡∏à‡∏£‡∏¥‡∏á\n",
    "pred_train = np.expm1(pipe.predict(X_train))\n",
    "true_train = np.expm1(y_train)\n",
    "\n",
    "pred_test = np.expm1(pipe.predict(X_test))\n",
    "true_test = np.expm1(y_test)\n",
    "\n",
    "# MSE/MAE/R2 train\n",
    "mse_tr  = mean_squared_error(true_train, pred_train)  # ‡πÑ‡∏°‡πà‡∏°‡∏µ squared=\n",
    "rmse_tr = np.sqrt(mse_tr)\n",
    "mae_tr  = mean_absolute_error(true_train, pred_train)\n",
    "r2_tr   = r2_score(true_train, pred_train)\n",
    "\n",
    "# MSE/MAE/R2 test\n",
    "mse_te  = mean_squared_error(true_test, pred_test)\n",
    "rmse_te = np.sqrt(mse_te)\n",
    "mae_te  = mean_absolute_error(true_test, pred_test)\n",
    "r2_te   = r2_score(true_test, pred_test)\n",
    "\n",
    "print(\"=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ===\")\n",
    "print(f\"Train RMSE: {rmse_tr:,.2f} | MAE: {mae_tr:,.2f} | R2: {r2_tr:.3f}\")\n",
    "print(f\" Test RMSE: {rmse_te:,.2f} | MAE: {mae_te:,.2f} | R2: {r2_te:.3f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 9) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• + ‡πÄ‡∏°‡∏ó‡∏≤‡∏î‡∏≤‡∏ó‡∏≤\n",
    "# ------------------------\n",
    "MODEL_PATH = \"house_price_pipeline_Train_10.joblib\"\n",
    "META_PATH = \"features.json\"\n",
    "\n",
    "joblib.dump(pipe, MODEL_PATH)\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"num\": FEATURES_NUM, \"cat\": FEATURES_CAT},\n",
    "              f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: {META_PATH}\")\n",
    "\n",
    "# ------------------------\n",
    "# 10) Helper: preview ‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå \"‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß\"\n",
    "# ------------------------\n",
    "def impute_preview(pipe: Pipeline, row_dict: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏∑‡∏ô dict ‡∏Ç‡∏≠‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á 9 ‡∏ï‡∏±‡∏ß '‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß' (‡∏Å‡πà‡∏≠‡∏ô scale/one-hot)\n",
    "    ‡πÉ‡∏ä‡πâ fillna(series) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡πÅ‡∏ô‡∏ß‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á ValueError)\n",
    "    \"\"\"\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° df 1 ‡πÅ‡∏ñ‡∏ß‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö FEATURES\n",
    "    row = {f: row_dict.get(f, np.nan) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "\n",
    "    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ preprocessor ‡∏Å‡πá‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏°‡∏≤\n",
    "    pre = pipe.named_steps.get(\"preprocessor\")\n",
    "    if pre is None:\n",
    "        return {k: (None if pd.isna(v) else v) for k, v in X_one.iloc[0].to_dict().items()}\n",
    "\n",
    "    # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á imputer ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "    try:\n",
    "        num_imp: SimpleImputer = pre.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "        cat_imp: SimpleImputer = pre.named_transformers_[\"cat\"].named_steps[\"imputer\"]\n",
    "    except Exception:\n",
    "        # ‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô/‡∏ä‡∏∑‡πà‡∏≠‡∏™‡πÄ‡∏ï‡πá‡∏õ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‚Üí ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "        return {k: row_dict.get(k, None) for k in FEATURES}\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå (index ‡∏ï‡∏£‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)\n",
    "    num_stats = pd.Series(num_imp.statistics_, index=FEATURES_NUM) if FEATURES_NUM else pd.Series(dtype=float)\n",
    "    cat_stats = pd.Series(cat_imp.statistics_, index=FEATURES_CAT) if FEATURES_CAT else pd.Series(dtype=object)\n",
    "\n",
    "    # ‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏ö‡∏ö column-wise ‡∏î‡πâ‡∏ß‡∏¢ fillna(series)\n",
    "    if FEATURES_NUM:\n",
    "        X_num = X_one[FEATURES_NUM].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        X_num = X_num.fillna(num_stats)\n",
    "    else:\n",
    "        X_num = pd.DataFrame()\n",
    "\n",
    "    if FEATURES_CAT:\n",
    "        X_cat = X_one[FEATURES_CAT].copy()\n",
    "        X_cat = X_cat.fillna(cat_stats)\n",
    "    else:\n",
    "        X_cat = pd.DataFrame()\n",
    "\n",
    "    # ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö FEATURES\n",
    "    if FEATURES_NUM and FEATURES_CAT:\n",
    "        X_imp = pd.concat([X_num, X_cat], axis=1)[FEATURES]\n",
    "    elif FEATURES_NUM:\n",
    "        X_imp = X_num[FEATURES]\n",
    "    else:\n",
    "        X_imp = X_cat[FEATURES]\n",
    "\n",
    "    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢: ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô float, ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÄ‡∏õ‡πá‡∏ô string/None\n",
    "    out = {}\n",
    "    for k, v in X_imp.iloc[0].to_dict().items():\n",
    "        if k in FEATURES_NUM:\n",
    "            out[k] = None if pd.isna(v) else float(v)\n",
    "        else:\n",
    "            out[k] = None if (isinstance(v, float) and pd.isna(v)) else str(v)\n",
    "    return out\n",
    "\n",
    "# ------------------------\n",
    "# 11) ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå + ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô \"‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß/‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "# ------------------------\n",
    "def predict_with_report(input_dict: Dict):\n",
    "    \"\"\"\n",
    "    - ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ (expm1)\n",
    "    - ‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô:\n",
    "        features_provided: ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å\n",
    "        features_filled:   ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≠‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ (imputed)\n",
    "    - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå\n",
    "    \"\"\"\n",
    "    # ‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå (‡πÑ‡∏ß‡πâ‡πÇ‡∏ä‡∏ß‡πå)\n",
    "    used_after_impute = impute_preview(pipe, input_dict)\n",
    "\n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö predict (‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ pipeline impute ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ú‡∏•)\n",
    "    row = {f: input_dict.get(f, None) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "    y_log = pipe.predict(X_one)[0]\n",
    "    y_hat = float(np.expm1(y_log))\n",
    "\n",
    "    # ‡∏à‡∏±‡∏î‡πÅ‡∏¢‡∏Å \"‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß\" vs \"‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "    provided, filled = {}, {}\n",
    "    for f in FEATURES:\n",
    "        if f in input_dict and input_dict[f] is not None:\n",
    "            provided[f] = used_after_impute[f]  # ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á\n",
    "        else:\n",
    "            filled[f] = used_after_impute[f]     # ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°\n",
    "\n",
    "    return {\n",
    "        \"predicted_price_usd\": round(y_hat, 2),\n",
    "        \"features_provided\": provided,\n",
    "        \"features_filled\": filled\n",
    "    }\n",
    "\n",
    "# ------------------------\n",
    "# 12) ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡πÄ‡∏Ñ‡∏™ (‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏ï‡πá‡∏°)\n",
    "# ------------------------\n",
    "examples = [\n",
    "    {\"LotArea\": 8500},\n",
    "    {\"LotArea\": 8500},\n",
    "    {\"LotArea\": 8500},]\n",
    "\n",
    "print(\"\\n=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    out = predict_with_report(ex)\n",
    "    print(f\"Case {i}: input={ex}\")\n",
    "    print(f\"‚Üí Predicted SalePrice: {out['predicted_price_usd']:,.2f} USD\")\n",
    "\n",
    "    print(\"‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\")\n",
    "    if out[\"features_provided\"]:\n",
    "        for k, v in out[\"features_provided\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏¢)\")\n",
    "\n",
    "    print(\"‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\")\n",
    "    if out[\"features_filled\"]:\n",
    "        for k, v in out[\"features_filled\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏£‡∏ö)\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3377b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc1ea52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regression metrics ===\n",
      "Train RMSE: 34,471.10 | MAE: 19,641.75 | R2: 0.801\n",
      " Test RMSE: 29,620.65 | MAE: 19,180.85 | R2: 0.886\n",
      "\n",
      "=== Classification-style metrics on price bins ===\n",
      "Accuracy: 0.7363 | F1-macro: 0.5845 | F1-weighted: 0.7357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    100-150k       0.81      0.79      0.80       113\n",
      "    150-200k       0.69      0.70      0.70        71\n",
      "    200-250k       0.57      0.74      0.64        34\n",
      "    250-500k       0.85      0.76      0.80        45\n",
      "     50-100k       0.64      0.67      0.65        24\n",
      "       500k+       1.00      0.33      0.50         3\n",
      "        <50k       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.74       292\n",
      "   macro avg       0.65      0.57      0.58       292\n",
      "weighted avg       0.74      0.74      0.74       292\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            P:<50k  P:50-100k  P:100-150k  P:150-200k  P:200-250k  P:250-500k  \\\n",
      "T:<50k           0          2           0           0           0           0   \n",
      "T:50-100k        0         16           8           0           0           0   \n",
      "T:100-150k       0          7          89          17           0           0   \n",
      "T:150-200k       0          0          12          50           8           1   \n",
      "T:200-250k       0          0           1           5          25           3   \n",
      "T:250-500k       0          0           0           0          11          34   \n",
      "T:500k+          0          0           0           0           0           2   \n",
      "\n",
      "            P:500k+  \n",
      "T:<50k            0  \n",
      "T:50-100k         0  \n",
      "T:100-150k        0  \n",
      "T:150-200k        0  \n",
      "T:200-250k        0  \n",
      "T:250-500k        0  \n",
      "T:500k+           1  \n",
      "\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: house_price_pipeline_Train_10.joblib\n",
      "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: features.json\n",
      "\n",
      "=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\n",
      "Case 1: input={'LotArea': 8500, 'OverallQual': 6, 'Neighborhood': 'CollgCr'}\n",
      "‚Üí Predicted SalePrice: 184,608.38 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - OverallQual: 6.0\n",
      "   - LotArea: 8500.0\n",
      "   - Neighborhood: CollgCr\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - TotalBsmtSF: 997.5\n",
      "   - GarageCars: 2.0\n",
      "   - Fireplaces: 1.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - GrLivArea: 1473.0\n",
      "   - FullBath: 2.0\n",
      "\n",
      "Case 2: input={'OverallQual': 7, 'GrLivArea': 1800, 'FullBath': 2, 'BedroomAbvGr': 3, 'Neighborhood': 'NAmes'}\n",
      "‚Üí Predicted SalePrice: 194,257.68 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - OverallQual: 7.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - GrLivArea: 1800.0\n",
      "   - FullBath: 2.0\n",
      "   - Neighborhood: NAmes\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - TotalBsmtSF: 997.5\n",
      "   - LotArea: 9600.0\n",
      "   - GarageCars: 2.0\n",
      "   - Fireplaces: 1.0\n",
      "\n",
      "Case 3: input={'LotArea': 12000, 'TotalBsmtSF': 900, 'GarageCars': 2, 'GrLivArea': 2200, 'FullBath': 2}\n",
      "‚Üí Predicted SalePrice: 190,951.88 USD\n",
      "‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\n",
      "   - TotalBsmtSF: 900.0\n",
      "   - LotArea: 12000.0\n",
      "   - GarageCars: 2.0\n",
      "   - GrLivArea: 2200.0\n",
      "   - FullBath: 2.0\n",
      "‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\n",
      "   - OverallQual: 6.0\n",
      "   - Fireplaces: 1.0\n",
      "   - BedroomAbvGr: 3.0\n",
      "   - Neighborhood: NAmes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_house_price.py\n",
    "# ====================\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô (Regression) ‡∏à‡∏≤‡∏Å Kaggle (train_cleaned.csv)\n",
    "# - ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå 9 ‡∏ï‡∏±‡∏ß + ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ SalePrice (log-transform)\n",
    "# - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ö‡∏ô test split ‚Üí RMSE/MAE/R¬≤\n",
    "# - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡πÅ‡∏ö‡∏ö Classification (Accuracy, F1, Classification Report, Confusion Matrix)\n",
    "#   ‡πÇ‡∏î‡∏¢ \"‡∏à‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ (bins)\" ‡πÉ‡∏´‡πâ y_true ‡πÅ‡∏•‡∏∞ y_pred ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Regression\n",
    "# - ‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô house_price_pipeline_Train_10.joblib ‡πÅ‡∏•‡∏∞ features.json\n",
    "# - ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö \"‡πÇ‡∏ä‡∏ß‡πå‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å\" ‡πÅ‡∏•‡∏∞ \"‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ (imputed)\"\n",
    "# - ‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å pandas: ‡πÉ‡∏ä‡πâ fillna(series) ‡πÅ‡∏ó‡∏ô where(...)\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    classification_report, confusion_matrix, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 1) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ------------------------\n",
    "DATA_PATH = \"train_cleaned.csv\"\n",
    "assert Path(DATA_PATH).exists(), f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DATA_PATH} ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# 2) ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå/‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢\n",
    "# ------------------------\n",
    "FEATURES_NUM = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "FEATURES_CAT = [\"Neighborhood\"]\n",
    "FEATURES = FEATURES_NUM + FEATURES_CAT\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "# ‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà target ‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏≠‡∏≠‡∏Å (‡∏Å‡∏±‡∏ô error)\n",
    "df = df.dropna(subset=[TARGET])\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "y = np.log1p(df[TARGET].astype(float))  # ‡πÅ‡∏õ‡∏•‡∏á log1p ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "\n",
    "# ------------------------\n",
    "# 3) ‡πÅ‡∏ö‡πà‡∏á train/test\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 4) Preprocessor (impute + encode + scale)\n",
    "# ------------------------\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_tf, FEATURES_NUM),\n",
    "    (\"cat\", cat_tf, FEATURES_CAT),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "# ------------------------\n",
    "model = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "\n",
    "# ------------------------\n",
    "# 6) Pipeline ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "# ------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", pre),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 7) ‡πÄ‡∏ó‡∏£‡∏ô\n",
    "# ------------------------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ------------------------\n",
    "# 8) ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Regression (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö sklearn ‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Å‡πà‡∏≤)\n",
    "# ------------------------\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å log ‚Üí ‡∏™‡πÄ‡∏Å‡∏•‡∏à‡∏£‡∏¥‡∏á\n",
    "pred_train = np.expm1(pipe.predict(X_train))\n",
    "true_train = np.expm1(y_train)\n",
    "\n",
    "pred_test = np.expm1(pipe.predict(X_test))\n",
    "true_test = np.expm1(y_test)\n",
    "\n",
    "# MSE/MAE/R2 train\n",
    "mse_tr  = mean_squared_error(true_train, pred_train)  # ‡πÑ‡∏°‡πà‡∏°‡∏µ squared=\n",
    "rmse_tr = np.sqrt(mse_tr)\n",
    "mae_tr  = mean_absolute_error(true_train, pred_train)\n",
    "r2_tr   = r2_score(true_train, pred_train)\n",
    "\n",
    "# MSE/MAE/R2 test\n",
    "mse_te  = mean_squared_error(true_test, pred_test)\n",
    "rmse_te = np.sqrt(mse_te)\n",
    "mae_te  = mean_absolute_error(true_test, pred_test)\n",
    "r2_te   = r2_score(true_test, pred_test)\n",
    "\n",
    "print(\"=== Regression metrics ===\")\n",
    "print(f\"Train RMSE: {rmse_tr:,.2f} | MAE: {mae_tr:,.2f} | R2: {r2_tr:.3f}\")\n",
    "print(f\" Test RMSE: {rmse_te:,.2f} | MAE: {mae_te:,.2f} | R2: {r2_te:.3f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 8.1) ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡πÅ‡∏ö‡∏ö Classification ‡∏ö‡∏ô '‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ (bins)'\n",
    "# ------------------------\n",
    "def price_to_bin(v):\n",
    "    if v <  50000:  return \"<50k\"\n",
    "    if v < 100000:  return \"50-100k\"\n",
    "    if v < 150000:  return \"100-150k\"\n",
    "    if v < 200000:  return \"150-200k\"\n",
    "    if v < 250000:  return \"200-250k\"\n",
    "    if v < 500000:  return \"250-500k\"\n",
    "    return \"500k+\"\n",
    "\n",
    "y_true_bins = pd.Series(true_test).map(price_to_bin)\n",
    "y_pred_bins = pd.Series(pred_test).map(price_to_bin)\n",
    "\n",
    "acc  = accuracy_score(y_true_bins, y_pred_bins)\n",
    "f1_macro    = f1_score(y_true_bins, y_pred_bins, average=\"macro\", zero_division=0)\n",
    "f1_weighted = f1_score(y_true_bins, y_pred_bins, average=\"weighted\", zero_division=0)\n",
    "\n",
    "print(\"\\n=== Classification-style metrics on price bins ===\")\n",
    "print(f\"Accuracy: {acc:.4f} | F1-macro: {f1_macro:.4f} | F1-weighted: {f1_weighted:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_bins, y_pred_bins, zero_division=0))\n",
    "\n",
    "labels_order = [\"<50k\",\"50-100k\",\"100-150k\",\"150-200k\",\"200-250k\",\"250-500k\",\"500k+\"]\n",
    "cm = confusion_matrix(y_true_bins, y_pred_bins, labels=labels_order)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"T:{l}\" for l in labels_order], columns=[f\"P:{l}\" for l in labels_order])\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "print(cm_df)\n",
    "\n",
    "# ------------------------\n",
    "# 9) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• + ‡πÄ‡∏°‡∏ó‡∏≤‡∏î‡∏≤‡∏ó‡∏≤\n",
    "# ------------------------\n",
    "MODEL_PATH = \"house_price_pipeline_Train_10.joblib\"\n",
    "META_PATH = \"features.json\"\n",
    "\n",
    "joblib.dump(pipe, MODEL_PATH)\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"features\": FEATURES, \"num\": FEATURES_NUM, \"cat\": FEATURES_CAT},\n",
    "              f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: {META_PATH}\")\n",
    "\n",
    "# ------------------------\n",
    "# 10) Helper: preview ‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå \"‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß\"\n",
    "# ------------------------\n",
    "def impute_preview(pipe: Pipeline, row_dict: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏∑‡∏ô dict ‡∏Ç‡∏≠‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á 9 ‡∏ï‡∏±‡∏ß '‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß' (‡∏Å‡πà‡∏≠‡∏ô scale/one-hot)\n",
    "    ‡πÉ‡∏ä‡πâ fillna(series) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡πÅ‡∏ô‡∏ß‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á ValueError)\n",
    "    \"\"\"\n",
    "    row = {f: row_dict.get(f, np.nan) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "\n",
    "    pre = pipe.named_steps.get(\"preprocessor\")\n",
    "    if pre is None:\n",
    "        return {k: (None if pd.isna(v) else v) for k, v in X_one.iloc[0].to_dict().items()}\n",
    "\n",
    "    try:\n",
    "        num_imp: SimpleImputer = pre.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "        cat_imp: SimpleImputer = pre.named_transformers_[\"cat\"].named_steps[\"imputer\"]\n",
    "    except Exception:\n",
    "        return {k: row_dict.get(k, None) for k in FEATURES}\n",
    "\n",
    "    num_stats = pd.Series(num_imp.statistics_, index=FEATURES_NUM) if FEATURES_NUM else pd.Series(dtype=float)\n",
    "    cat_stats = pd.Series(cat_imp.statistics_, index=FEATURES_CAT) if FEATURES_CAT else pd.Series(dtype=object)\n",
    "\n",
    "    if FEATURES_NUM:\n",
    "        X_num = X_one[FEATURES_NUM].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        X_num = X_num.fillna(num_stats)\n",
    "    else:\n",
    "        X_num = pd.DataFrame()\n",
    "\n",
    "    if FEATURES_CAT:\n",
    "        X_cat = X_one[FEATURES_CAT].copy()\n",
    "        X_cat = X_cat.fillna(cat_stats)\n",
    "    else:\n",
    "        X_cat = pd.DataFrame()\n",
    "\n",
    "    if FEATURES_NUM and FEATURES_CAT:\n",
    "        X_imp = pd.concat([X_num, X_cat], axis=1)[FEATURES]\n",
    "    elif FEATURES_NUM:\n",
    "        X_imp = X_num[FEATURES]\n",
    "    else:\n",
    "        X_imp = X_cat[FEATURES]\n",
    "\n",
    "    out = {}\n",
    "    for k, v in X_imp.iloc[0].to_dict().items():\n",
    "        if k in FEATURES_NUM:\n",
    "            out[k] = None if pd.isna(v) else float(v)\n",
    "        else:\n",
    "            out[k] = None if (isinstance(v, float) and pd.isna(v)) else str(v)\n",
    "    return out\n",
    "\n",
    "# ------------------------\n",
    "# 11) ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå + ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô \"‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß/‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ\"\n",
    "# ------------------------\n",
    "def predict_with_report(input_dict: Dict):\n",
    "    \"\"\"\n",
    "    - ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ (expm1)\n",
    "    - ‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô:\n",
    "        features_provided: ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å\n",
    "        features_filled:   ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≠‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ (imputed)\n",
    "    - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¥‡∏°‡∏û‡∏¥‡∏ß‡∏ï‡πå\n",
    "    \"\"\"\n",
    "    used_after_impute = impute_preview(pipe, input_dict)\n",
    "\n",
    "    row = {f: input_dict.get(f, None) for f in FEATURES}\n",
    "    X_one = pd.DataFrame([row], columns=FEATURES)\n",
    "    y_log = pipe.predict(X_one)[0]\n",
    "    y_hat = float(np.expm1(y_log))\n",
    "\n",
    "    provided, filled = {}, {}\n",
    "    for f in FEATURES:\n",
    "        if f in input_dict and input_dict[f] is not None:\n",
    "            provided[f] = used_after_impute[f]\n",
    "        else:\n",
    "            filled[f] = used_after_impute[f]\n",
    "\n",
    "    return {\n",
    "        \"predicted_price_usd\": round(y_hat, 2),\n",
    "        \"features_provided\": provided,\n",
    "        \"features_filled\": filled\n",
    "    }\n",
    "\n",
    "# ------------------------\n",
    "# 12) ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå 3 ‡πÄ‡∏Ñ‡∏™ (‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏ï‡πá‡∏°)\n",
    "# ------------------------\n",
    "examples = [\n",
    "    {\"LotArea\": 8500, \"OverallQual\": 6, \"Neighborhood\": \"CollgCr\"},\n",
    "    {\"OverallQual\": 7, \"GrLivArea\": 1800, \"FullBath\": 2, \"BedroomAbvGr\": 3, \"Neighborhood\": \"NAmes\"},\n",
    "    {\"LotArea\": 12000, \"TotalBsmtSF\": 900, \"GarageCars\": 2, \"GrLivArea\": 2200, \"FullBath\": 2},\n",
    "]\n",
    "\n",
    "print(\"\\n=== ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏¢‡∏Å '‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß' / '‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ') ===\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "    out = predict_with_report(ex)\n",
    "    print(f\"Case {i}: input={ex}\")\n",
    "    print(f\"‚Üí Predicted SalePrice: {out['predicted_price_usd']:,.2f} USD\")\n",
    "\n",
    "    print(\"‚Üí Features (‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß):\")\n",
    "    if out[\"features_provided\"]:\n",
    "        for k, v in out[\"features_provided\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏¢)\")\n",
    "\n",
    "    print(\"‚Üí Features (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ):\")\n",
    "    if out[\"features_filled\"]:\n",
    "        for k, v in out[\"features_filled\"].items():\n",
    "            print(f\"   - {k}: {v}\")\n",
    "    else:\n",
    "        print(\"   (‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Äî ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏£‡∏ö)\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38de59d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 29,620.65 | MAE: 19,180.85 | R¬≤: 0.886\n",
      "‚úÖ Saved packed model to house_price_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# train_and_pack.py\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô RidgeCV + ‡∏´‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ HousePriceModel (predict + suggest_profiles)\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "FEATURES_NUM = [\n",
    "    \"OverallQual\", \"TotalBsmtSF\", \"LotArea\", \"GarageCars\",\n",
    "    \"Fireplaces\", \"BedroomAbvGr\", \"GrLivArea\", \"FullBath\"\n",
    "]\n",
    "FEATURES_CAT = [\"Neighborhood\"]\n",
    "FEATURES_ALL = FEATURES_NUM + FEATURES_CAT\n",
    "TARGET = \"SalePrice\"\n",
    "INT_LIKE = [\"OverallQual\",\"GarageCars\",\"Fireplaces\",\"BedroomAbvGr\",\"FullBath\"]\n",
    "\n",
    "class HousePriceModel:\n",
    "    \"\"\"‡∏ö‡∏£‡∏£‡∏à‡∏∏ Pipeline + ‡∏î‡∏≤‡∏ï‡πâ‡∏≤‡πÄ‡∏ö‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á 3 ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\"\"\"\n",
    "    def __init__(self, pipe: Pipeline, df_train: pd.DataFrame):\n",
    "        self.pipe = pipe\n",
    "        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏û‡∏∑‡πà‡∏≠ suggestion)\n",
    "        df = df_train.copy()\n",
    "        for c in FEATURES_ALL:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        self.df = df[FEATURES_ALL].copy()\n",
    "\n",
    "    # ---------- Utils ----------\n",
    "    def _coerce_row_types(self, d: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        d = dict(d)\n",
    "        for k in INT_LIKE:\n",
    "            if k in d and d[k] is not None and not pd.isna(d[k]):\n",
    "                d[k] = int(round(float(d[k])))\n",
    "        if \"LotArea\" in d and d[\"LotArea\"] is not None and not pd.isna(d[\"LotArea\"]):\n",
    "            d[\"LotArea\"] = float(d[\"LotArea\"])\n",
    "        if \"Neighborhood\" in d and d[\"Neighborhood\"] is not None and not pd.isna(d[\"Neighborhood\"]):\n",
    "            d[\"Neighborhood\"] = str(d[\"Neighborhood\"])\n",
    "        return d\n",
    "\n",
    "    def _predict_price(self, row: Dict[str, Any]) -> float:\n",
    "        X = pd.DataFrame([{c: row.get(c, np.nan) for c in FEATURES_ALL}], columns=FEATURES_ALL)\n",
    "        y_log = self.pipe.predict(X)[0]\n",
    "        return float(np.expm1(y_log))\n",
    "\n",
    "    def _group_by_lotarea(self, lot: float, pct_window: float = 0.15, min_rows: int = 50) -> pd.DataFrame:\n",
    "        g = pd.DataFrame()\n",
    "        for mul in [1.0, 1.5, 2.0, 3.0]:\n",
    "            low, high = lot*(1 - pct_window*mul), lot*(1 + pct_window*mul)\n",
    "            g = self.df[(self.df[\"LotArea\"] >= low) & (self.df[\"LotArea\"] <= high)].copy()\n",
    "            if len(g) >= min_rows:\n",
    "                break\n",
    "        if g.empty:\n",
    "            g = self.df.copy()\n",
    "        if \"Neighborhood\" in g.columns:\n",
    "            g = g.dropna(subset=[\"Neighborhood\"])\n",
    "        return g.reset_index(drop=True)\n",
    "\n",
    "    # ---------- Public: prediction ----------\n",
    "    def predict(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"‡∏£‡∏±‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏Å‡πá‡πÑ‡∏î‡πâ ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤ + ‡πÅ‡∏™‡∏î‡∏á preview ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (median/mode ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ)\"\"\"\n",
    "        row = self._coerce_row_types({k: v for k, v in payload.items() if v is not None})\n",
    "        price = self._predict_price(row)\n",
    "\n",
    "        # preview ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå)\n",
    "        g = self.df\n",
    "        preview = {}\n",
    "        for c in FEATURES_NUM:\n",
    "            preview[c] = row.get(c, float(g[c].median()))\n",
    "        for c in FEATURES_CAT:\n",
    "            preview[c] = row.get(c, str(g[c].mode(dropna=True).iloc[0]) if g[c].notna().any() else None)\n",
    "\n",
    "        return {\n",
    "            \"predicted_price_usd\": round(price, 2),\n",
    "            \"features_used_preview\": self._coerce_row_types(preview)\n",
    "        }\n",
    "\n",
    "    # ---------- Public: 3 suggestions ----------\n",
    "    def suggest_profiles(\n",
    "        self,\n",
    "        lotarea: float,\n",
    "        method: str = \"neighborhood\",\n",
    "        pct_window: float = 0.15\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ‡∏™‡∏£‡πâ‡∏≤‡∏á 3 ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå (features ‡∏Ñ‡∏£‡∏ö 9) + ‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "        method: 'neighborhood' | 'quantile' | 'knn'\n",
    "        \"\"\"\n",
    "        lot = float(lotarea)\n",
    "        group = self._group_by_lotarea(lot, pct_window=pct_window, min_rows=60)\n",
    "\n",
    "        if method == \"neighborhood\":\n",
    "            items = self._suggest_neighborhood(group, lot, n=3)\n",
    "        elif method == \"quantile\":\n",
    "            items = self._suggest_quantile(group, lot, jitter=0.05)\n",
    "        elif method == \"knn\":\n",
    "            items = self._suggest_knn(group, lot, k=5, n=3, jitter=0.03)\n",
    "        else:\n",
    "            raise ValueError(\"method must be one of: neighborhood | quantile | knn\")\n",
    "\n",
    "        return {\n",
    "            \"summary\": {\n",
    "                \"method\": method,\n",
    "                \"n_in_group\": int(len(group)),\n",
    "                \"lotarea_input\": lot,\n",
    "                \"lotarea_range\": [int(group[\"LotArea\"].min()), int(group[\"LotArea\"].max())],\n",
    "                \"neighborhood_top\": group[\"Neighborhood\"].value_counts().head(3).to_dict()\n",
    "            },\n",
    "            \"items\": items\n",
    "        }\n",
    "\n",
    "    # ----- methods impl -----\n",
    "    def _suggest_neighborhood(self, group_df: pd.DataFrame, lot: float, n: int = 3) -> List[Dict[str, Any]]:\n",
    "        df = group_df.copy()\n",
    "        df[\"_diff\"] = (df[\"LotArea\"] - lot).abs()\n",
    "        df = df.sort_values(\"_diff\").reset_index(drop=True)\n",
    "\n",
    "        picks = []\n",
    "        if len(df) >= 1: picks.append(df.iloc[0])           # ‡πÉ‡∏Å‡∏•‡πâ‡∏™‡∏∏‡∏î\n",
    "        if len(df) >= 3: picks.append(df.iloc[len(df)//2])  # ‡∏Å‡∏•‡∏≤‡∏á\n",
    "        if len(df) >= 2: picks.append(df.iloc[-1])          # ‡∏´‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î\n",
    "\n",
    "        items = []\n",
    "        for r in picks[:n]:\n",
    "            feat = {c: r[c] for c in FEATURES_ALL}\n",
    "            feat = self._coerce_row_types(feat)\n",
    "            items.append({\n",
    "                \"features\": feat,\n",
    "                \"predicted_price_usd\": round(self._predict_price(feat), 2)\n",
    "            })\n",
    "        return items\n",
    "\n",
    "    def _suggest_quantile(self, group_df: pd.DataFrame, lot: float, jitter: float = 0.05) -> List[Dict[str, Any]]:\n",
    "        g = group_df.copy()\n",
    "        q = g[FEATURES_NUM].quantile([0.25, 0.5, 0.75]).to_dict(orient=\"index\")\n",
    "        modes = g[\"Neighborhood\"].value_counts().index.tolist()[:3]\n",
    "        if len(modes) < 3:\n",
    "            modes += ([modes[-1]] * (3 - len(modes))) if modes else [\"NAmes\", \"CollgCr\", \"OldTown\"]\n",
    "\n",
    "        items = []\n",
    "        for qn, neigh in zip([0.25, 0.5, 0.75], modes):\n",
    "            base = {k: q[qn][k] for k in FEATURES_NUM}\n",
    "            base[\"LotArea\"] = lot * (1.0 + np.random.uniform(-jitter, jitter))\n",
    "            base[\"Neighborhood\"] = neigh\n",
    "            feat = self._coerce_row_types(base)\n",
    "            items.append({\n",
    "                \"features\": feat,\n",
    "                \"predicted_price_usd\": round(self._predict_price(feat), 2)\n",
    "            })\n",
    "        return items\n",
    "\n",
    "    def _suggest_knn(self, group_df: pd.DataFrame, lot: float, k: int = 5, n: int = 3, jitter: float = 0.03) -> List[Dict[str, Any]]:\n",
    "        g = group_df.copy()\n",
    "        g_num = g.copy()\n",
    "        neigh_map = {v: i for i, v in enumerate(g[\"Neighborhood\"].fillna(\"NA\").unique())}\n",
    "        g_num[\"Neighborhood\"] = g[\"Neighborhood\"].map(neigh_map).astype(float)\n",
    "\n",
    "        imputer = KNNImputer(n_neighbors=k, weights=\"distance\")\n",
    "        imputer.fit(g_num[FEATURES_ALL])\n",
    "\n",
    "        items = []\n",
    "        for j in [-jitter, 0.0, jitter]:\n",
    "            row = {c: np.nan for c in FEATURES_ALL}\n",
    "            row[\"LotArea\"] = lot * (1.0 + (np.random.uniform(-abs(j), abs(j)) if j != 0 else 0.0))\n",
    "            df_row = pd.DataFrame([row], columns=FEATURES_ALL)\n",
    "            df_row[\"Neighborhood\"] = np.nan\n",
    "            pred = imputer.transform(df_row)[0]\n",
    "            d = {FEATURES_ALL[i]: pred[i] for i in range(len(FEATURES_ALL))}\n",
    "            inv_neigh = {v: k for k, v in neigh_map.items()}\n",
    "            d[\"Neighborhood\"] = inv_neigh.get(int(round(d[\"Neighborhood\"])), \"NAmes\")\n",
    "            feat = self._coerce_row_types(d)\n",
    "            items.append({\n",
    "                \"features\": feat,\n",
    "                \"predicted_price_usd\": round(self._predict_price(feat), 2)\n",
    "            })\n",
    "        return items[:n]\n",
    "\n",
    "\n",
    "# ================== ‡πÄ‡∏ó‡∏£‡∏ô + ‡πÅ‡∏û‡πá‡∏Å + ‡πÄ‡∏ã‡∏ü ==================\n",
    "DATA_PATH = \"train_cleaned.csv\"\n",
    "assert Path(DATA_PATH).exists(), \"‡πÑ‡∏°‡πà‡∏û‡∏ö train_cleaned.csv\"\n",
    "df = pd.read_csv(DATA_PATH).dropna(subset=[TARGET])\n",
    "\n",
    "X = df[FEATURES_ALL].copy()\n",
    "y = np.log1p(df[TARGET].astype(float))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "cat_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "pre = ColumnTransformer([(\"num\", num_tf, FEATURES_NUM), (\"cat\", cat_tf, FEATURES_CAT)])\n",
    "\n",
    "model = RidgeCV(alphas=(0.1, 1.0, 10.0))\n",
    "pipe = Pipeline([(\"preprocessor\", pre), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "pred_test = np.expm1(pipe.predict(X_test)); true_test = np.expm1(y_test)\n",
    "rmse = mean_squared_error(true_test, pred_test) ** 0.5\n",
    "mae  = mean_absolute_error(true_test, pred_test)\n",
    "r2   = r2_score(true_test, pred_test)\n",
    "print(f\"Test RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | R¬≤: {r2:.3f}\")\n",
    "\n",
    "# ‡πÅ‡∏û‡πá‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü\n",
    "packed = HousePriceModel(pipe, df_train=df)\n",
    "joblib.dump(packed, \"house_price_model.joblib\")\n",
    "print(\"‚úÖ Saved packed model to house_price_model.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
